{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb46e425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\czhao\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\czhao\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\czhao\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "def read_file_by_lines(file):\n",
    "    try:\n",
    "        with open(file, 'r', encoding='latin-1') as f:\n",
    "            lines = f.read().splitlines()\n",
    "        return lines\n",
    "    except:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            lines = f.read().splitlines()\n",
    "        return lines\n",
    "    \n",
    "    \n",
    "def extract_date(string):\n",
    "    # Extract the value using regular expressions\n",
    "    match = re.search(r'(\\d{6})_(\\d+)', string)\n",
    "\n",
    "    if match:\n",
    "        extracted_value = match.group(2)\n",
    "        return(int(extracted_value))\n",
    "    \n",
    "def extract_time(string):\n",
    "    # Extract the value using regular expressions\n",
    "    match = re.search(r'_(\\d+)_', string)\n",
    "\n",
    "    if match:\n",
    "        extracted_value = match.group(1)\n",
    "        return(extracted_value)\n",
    "    \n",
    "def extract_timestamp(time):\n",
    "    \n",
    "    # Extract hour, minute, and second using regular expressions\n",
    "    match = re.search(r\"\\[(\\d{3}):(\\d{2}):(\\d{2});((\\d{3})|(\\d{2}))\\]\", time)\n",
    "\n",
    "    if match:\n",
    "        hour = match.group(1)\n",
    "        minute = match.group(2)\n",
    "        second = match.group(3)\n",
    "        millisecond = match.group(4)\n",
    "        \n",
    "        return [int(hour), int(minute), int(second), int(millisecond)]\n",
    "    else:\n",
    "        print(time)\n",
    "\n",
    "def get_frag_in_elapse_time(df, based_col, new_col, gap_time=35):\n",
    "    # Assuming you have a DataFrame named 'df' with appropriate columns\n",
    "\n",
    "    last_sent = 0\n",
    "    next_sent = 0\n",
    "    elapse_time0 = 0\n",
    "#     gap_time = 60\n",
    "    \n",
    "    df[new_col] = pd.Series(dtype='int')\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        frag_count_gt1 = row[based_col]\n",
    "        time_span = row['time_span']\n",
    "\n",
    "        next_sent = index\n",
    "        if frag_count_gt1 > 0:\n",
    "            # Set indicator = 1 and update last_sent\n",
    "            df.at[index, new_col] = 1\n",
    "            last_sent = index\n",
    "            elapse_time0 = 0\n",
    "        else:\n",
    "            if last_sent == 0:\n",
    "                # Set indicator = 0 if no matches found yet\n",
    "                df.at[index, new_col] = 0\n",
    "            else:\n",
    "\n",
    "                elapse_time0 += time_span\n",
    "\n",
    "                if elapse_time0 <= gap_time:\n",
    "                    # Set indicator = 1 if time span <= gap_time\n",
    "                    df.at[index, new_col] = 1\n",
    "                else:\n",
    "                    # Set indicator = 0 for rows between last_sent+1 and next_sent-1\n",
    "                    df.loc[last_sent + 1:next_sent, new_col] = 0\n",
    "                    elapse_time0 = 0\n",
    "                    last_sent=0\n",
    "\n",
    "def CC_process(cc_files_dic, transcript_file, output_file_path, date):\n",
    "    print(transcript_file)\n",
    "#     set and extract start time of 9am\n",
    "    if date[-3:-2] == '6' or date[-3:-2] == '7':\n",
    "        Nine_AM_time = 130000\n",
    "    else:\n",
    "        Nine_AM_time = 140000\n",
    "        \n",
    "    \n",
    "    df_transcript = pd.read_excel(transcript_file, index_col=0)  \n",
    "    \n",
    "    df_transcript = df_transcript[df_transcript.columns.drop(list(df_transcript.filter(regex='Unnamed')))].reset_index()\n",
    "    \n",
    "    with pd.ExcelWriter(output_file_path) as writer:\n",
    "    \n",
    "        for news_type, cc_files in cc_files_dic.items():\n",
    "\n",
    "            target_ls = []\n",
    "\n",
    "            for file in glob.glob(cc_files):\n",
    "                target_ls.append(file)\n",
    "                \n",
    "            if target_ls != []:\n",
    "\n",
    "                df = pd.DataFrame(target_ls, columns=['File Names'])\n",
    "\n",
    "                df['clip_starttime'] = df['File Names'].apply(extract_date)\n",
    "                df['DATE'] = df['File Names'].apply(extract_time)\n",
    "                df['raw_input'] = df.apply(lambda x: read_file_by_lines(x['File Names']), axis=1)\n",
    "                df = df.explode('raw_input').reset_index(drop=True)\n",
    "                df[['hour', 'minute', 'second', 'millisecond']] = df.apply(lambda x: extract_timestamp(x['raw_input']), axis=1, result_type=\"expand\")\n",
    "                df = df.sort_values(['clip_starttime', 'hour', 'minute', 'second', 'millisecond']).reset_index(drop=True)\n",
    "                \n",
    "                df['raw_input'] = df['raw_input'].apply(lambda x: x.split(']')[1].strip('>- ')).fillna('')\n",
    "                df['number_of_words'] = df['raw_input'].apply(lambda x: len(re.sub(r'[^\\w\\s]', '', x).split(' ')))\n",
    "                df['cleaned_text'] = df['raw_input'].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x).replace(\" \", \"\")))\n",
    "                df['real_time_clip_seconds'] = df['hour']*3600+df['minute']*60+df['second']+(df['clip_starttime']-Nine_AM_time)/10000*3600+32400\n",
    "                df_transcript['cleaned_sentence'] = df_transcript['sentence'].fillna('').apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x).replace(\" \", \"\")))\n",
    "                df_transcript['trans_timestamp_seconds'] = df_transcript['time_hour_part']*3600+df_transcript['time_min_part']*60+df_transcript['time_sec_part']\n",
    "                df['occurrence_sent_num'] = df.apply(lambda x: [df_transcript['sentence_num'][idx] for idx, sent in enumerate(df_transcript['cleaned_sentence'].values) if x['cleaned_text'].lower() in sent.lower()] if x['number_of_words']>1 else '' , axis=1)\n",
    "                df['timed_matches'] = df.apply(lambda x: [sent_num for (sent_num, timed_match) in \\\n",
    "                                                  zip(x.occurrence_sent_num ,[Time_tol > abs(x.real_time_clip_seconds - \\\n",
    "                                                df_transcript['trans_timestamp_seconds'][df_transcript['sentence_num'].tolist().index(i)]) \\\n",
    "                                                for i in x['occurrence_sent_num']]) if timed_match], axis=1)\n",
    "\n",
    "                df.to_excel(writer, sheet_name=news_type + '_Closed_Captioning')\n",
    "\n",
    "                occurrence_dic = Counter(list(itertools.chain.from_iterable(df[df['cleaned_text'].str.len()>1]['timed_matches'].values)))\n",
    "\n",
    "                df_transcript['Frag_count_gt_'+news_type] = df_transcript['sentence_num'].apply(lambda x: occurrence_dic[x] if x in occurrence_dic else 0)\n",
    "\n",
    "                get_frag_in_elapse_time(df_transcript, 'Frag_count_gt_'+news_type, 'Frag_in_elasp_time_'+news_type)\n",
    "\n",
    "                # Add two dummy columns\n",
    "                df_transcript['dummy_preceding'+news_type] = 0\n",
    "                df_transcript['dummy_subsequent'+news_type] = 0\n",
    "\n",
    "                # Iterate over each row in the DataFrame\n",
    "                for index, row in df_transcript.iterrows():\n",
    "                    # Calculate the sum of the preceding 5 sentences\n",
    "                    if index > 4:\n",
    "                        preceding_sum = df_transcript['Frag_in_elasp_time_'+news_type][index - 5:index].sum()\n",
    "                    else:\n",
    "                        preceding_sum = df_transcript['Frag_in_elasp_time_'+news_type][0:index].sum()\n",
    "\n",
    "                    # Calculate the sum of the subsequent 5 sentences or till the end of the file\n",
    "                    if index < len(df) - 5:\n",
    "                        subsequent_sum = df_transcript['Frag_in_elasp_time_'+news_type][index + 1:index + 6].sum()\n",
    "                    else:\n",
    "                        subsequent_sum = df_transcript['Frag_in_elasp_time_'+news_type][index + 1:].sum()\n",
    "\n",
    "                    # Set dummy variables\n",
    "                    df_transcript.at[index, 'dummy_preceding'+news_type] = 1 if preceding_sum > 0 else 0\n",
    "                    df_transcript.at[index, 'dummy_subsequent'+news_type] = 1 if subsequent_sum > 0 else 0\n",
    "\n",
    "                # Set the values in the third column based on the conditions\n",
    "                df_transcript['Frag_range5'+news_type] = 0\n",
    "\n",
    "                for index, row in df_transcript.iterrows():\n",
    "                    second_value = row['Frag_in_elasp_time_'+news_type]\n",
    "                    dummy_preceding = row['dummy_preceding'+news_type]\n",
    "                    dummy_subsequent = row['dummy_subsequent'+news_type]\n",
    "\n",
    "                    if second_value == 0:\n",
    "                        df_transcript.at[index, 'Frag_range5'+news_type] = 0\n",
    "                    elif second_value == 1 and dummy_preceding == 0 and dummy_subsequent == 0:\n",
    "                        df_transcript.at[index, 'Frag_range5'+news_type] = 0\n",
    "                    else:\n",
    "                        df_transcript.at[index, 'Frag_range5'+news_type] = 1\n",
    "\n",
    "                # Drop the dummy columns if they are no longer needed\n",
    "                df_transcript = df_transcript.drop(['dummy_preceding'+news_type, 'dummy_subsequent'+news_type], axis=1)\n",
    "            \n",
    "        df_transcript.to_excel(writer, sheet_name='Transcript')\n",
    "        \n",
    "\n",
    "Time_tol = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2425f7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how to process all files\n",
    "all_folders = glob.glob(\"0_ChenZhao/*\")\n",
    "dates = [i[-8:] for i in all_folders]\n",
    "transcript_files = glob.glob(\"interuption_transcriptsv4/*\")\n",
    "transcript_date = [i[-19:-11] for i in glob.glob(\"interuption_transcriptsv4/*\")]\n",
    "target_files = [transcript_files[transcript_date.index(date)] for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03042222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases for testing one output\n",
    "all_folders = ['0_ChenZhao/cc5_20100224']\n",
    "target_files = ['interuption_transcriptsv4/Bernanke_20100224_v10_3_with_part2.xlsx']\n",
    "dates = ['20100224']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc6dc3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interuption_transcriptsv4/Bernanke_20100224_v10_3_with_part2.xlsx\n"
     ]
    }
   ],
   "source": [
    "for folder, transcript, date in zip(all_folders,target_files, dates):\n",
    "    cc_files_dic = {\"CNBC\": \"{}/CNBC*.txt\".format(folder), \"BLOOMBERG\": \"{}/BLOOMBERG*.txt\".format(folder), \"FBC\": \"{}/FBC*.txt\".format(folder)}\n",
    "\n",
    "    CC_process(cc_files_dic, transcript, 'output_folder/CC_output_' + date + '.xlsx', date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
