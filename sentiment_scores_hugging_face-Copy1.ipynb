{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac575e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.conda/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import nltk\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import xml.etree.cElementTree as et\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import nltk.data\n",
    "from os import listdir\n",
    "import pysent3 as ps\n",
    "from os.path import isfile, join\n",
    "import eng_spacysentiment\n",
    "nlp_spacy = eng_spacysentiment.load()\n",
    "\n",
    "# nltk_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "  def __init__(self, text, targets, tokenizer, max_len):\n",
    "    self.text = text\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  def __len__(self):\n",
    "    return len(self.text)\n",
    "  def __getitem__(self, item):\n",
    "    text = str(self.text[item])\n",
    "    target = self.targets[item]\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      text,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding = 'max_length', #pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "      truncation=True\n",
    "    )\n",
    "    return {\n",
    "      'text_text': text,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    self.drop = nn.Dropout(p=0.3)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask, \n",
    "      return_dict=False\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "    return self.out(output)\n",
    "\n",
    "\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size, col):\n",
    "  ds = TextDataset(\n",
    "    text=df[col].to_numpy(),\n",
    "    targets=df.sentiment_value.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4\n",
    "  )\n",
    "\n",
    "\n",
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "  review_texts = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      texts = d[\"text_text\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      review_texts.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(outputs)\n",
    "      real_values.extend(targets)\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return review_texts, predictions, prediction_probs, real_values\n",
    "\n",
    "RANDOM_SEED = 0 \n",
    "PRE_TRAINED_MODEL_NAME = 'bert-large-uncased'\n",
    "FINBERT_MODEL_NAME = 'finbert'\n",
    "MAX_LEN = 85 \n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 8\n",
    "LEARNING_RATE = 1e-5\n",
    "TEST_DATA_PERCENT = 0.30\n",
    "\n",
    "def get_finbert_sentiment(sentence):\n",
    "    ###\n",
    "    # labels = {0:'neutral', 1:'positive',2:'negative'}\n",
    "    ###\n",
    "\n",
    "    inputs = tokenizer_finbert(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = finbert_model(**inputs)[0]\n",
    "#     return np.argmax(outputs.detach().numpy())\n",
    "    return nn.Softmax(dim=1)(outputs).detach().numpy()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b7f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "os.chdir(\"/home/ec2-user/SageMaker/Getting Started/2022.05.25/ahkz_sentiment_classifier/ahkz_sentiment_classifier/multifiles/part2_for_chen\")\n",
    "csv_ls = []\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    csv_ls.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b6c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/home/ec2-user/SageMaker/Getting Started/2022.05.25/ahkz_sentiment_classifier/ahkz_sentiment_classifier/'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained('/home/ec2-user/SageMaker/bert-large-uncased/')\n",
    "sent_model = torch.load(ROOT_PATH + 'model/3_class_fed_testimony_bert_large_uncased_best_model.pt', map_location = device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f666a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_finbert = BertTokenizer.from_pretrained('/home/ec2-user/SageMaker/finbert/')\n",
    "finbert_model = BertForSequenceClassification.from_pretrained('/home/ec2-user/SageMaker/finbert/', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af8b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_file(files):\n",
    "    source_folder = \"/home/ec2-user/SageMaker/Getting Started/2022.05.25/ahkz_sentiment_classifier/ahkz_sentiment_classifier/multifiles/part2_for_chen/\"\n",
    "    target_folder = \"/home/ec2-user/SageMaker/Getting Started/2022.05.25/ahkz_sentiment_classifier/ahkz_sentiment_classifier/multifiles/part2_for_chen_result/\"\n",
    "    column_ls = ['sentence_before', 'sentence_with_the_quote', 'sentence_after', 'concat_sentence']\n",
    "    for file in files:\n",
    "        try:\n",
    "            df = pd.read_csv(source_folder+file)\n",
    "#             df = df.iloc[:,:-2]\n",
    "            column_ls = [df.columns[i] for i in [4,12]]\n",
    "        \n",
    "            for col in column_ls:\n",
    "                # FinBERT\n",
    "                df['finbert_score'] = df[col].apply(lambda x: get_finbert_sentiment(x) if x!='' else ['','',''])\n",
    "\n",
    "                df[['finbert_neutral_'+col,'finbert_positive_'+col,'finbert_negative_'+col]] = \\\n",
    "                                pd.DataFrame(df['finbert_score'].tolist(), index= df.index)\n",
    "\n",
    "                df = df.drop(['finbert_score'], axis=1)\n",
    "\n",
    "                #ahkz\n",
    "                df['sentiment_value'] = 0\n",
    "\n",
    "                testimony_data_loader = create_data_loader(df, tokenizer, MAX_LEN, BATCH_SIZE, col)\n",
    "                testimony_texts, predictions, prediction_probs, real_values = get_predictions(sent_model, testimony_data_loader)\n",
    "\n",
    "                pred_numpy = predictions.numpy()\n",
    "                pred_probs = prediction_probs.numpy()\n",
    "                ms_pred = real_values.numpy()\n",
    "\n",
    "                df['sentiment_head'] = pred_numpy\n",
    "                df['sentiment_head'].replace({2: -1}, inplace=True)\n",
    "                df.drop('sentiment_value', axis=1, inplace=True)\n",
    "                df = df.rename(columns={\"sentiment_head\": \"ahkz_score_\"+col})\n",
    "\n",
    "                #pysent3\n",
    "                hiv4 = ps.HIV4()\n",
    "                df['pysent3'] = df[col].apply(lambda x: hiv4.get_score(hiv4.tokenize(x)))\n",
    "\n",
    "                pysent3_df = df['pysent3'].apply(pd.Series).rename(columns={\"Positive\": \"pysent3_Positive_\"+col, \\\n",
    "                                                               \"Negative\": \"pysent3_Negative_\"+col, \\\n",
    "                                                               \"Polarity\": \"pysent3_Polarity_\"+col, \\\n",
    "                                                               \"Subjectivity\": \"pysent3_Subjectivity_\"+col})\n",
    "\n",
    "                df = pd.concat([df, pysent3_df], axis=1)\n",
    "\n",
    "                df = df.drop(columns=['pysent3'])\n",
    "                \n",
    "                df['spacy_senti_'+col] = df[col].apply(lambda x: nlp_spacy(x).cats['positive'])\n",
    "\n",
    "            df.to_csv(target_folder + file, index =False)\n",
    "        except:\n",
    "            print(source_folder+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "491deff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_file(csv_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f85174e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/Getting Started/2022.05.25/ahkz_sentiment_classifier/ahkz_sentiment_classifier/multifiles/source'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25cafd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tzip warning: zip file empty\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r ../breakingnews.zip . -i ../target/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "defc6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../target/20120718CNBC_breakingnews_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "271af7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp 1</th>\n",
       "      <th>date</th>\n",
       "      <th>9am est stamp</th>\n",
       "      <th>fed chair</th>\n",
       "      <th>text</th>\n",
       "      <th>standardized</th>\n",
       "      <th>policy ind (1=testimony related, 0=not policy related, 99=other</th>\n",
       "      <th>topic indicator</th>\n",
       "      <th>type of news indicator</th>\n",
       "      <th>first timestamp of group</th>\n",
       "      <th>...</th>\n",
       "      <th>spacy_senti_text</th>\n",
       "      <th>finbert_neutral_text.1</th>\n",
       "      <th>finbert_positive_text.1</th>\n",
       "      <th>finbert_negative_text.1</th>\n",
       "      <th>ahkz_score_text.1</th>\n",
       "      <th>pysent3_Positive_text.1</th>\n",
       "      <th>pysent3_Negative_text.1</th>\n",
       "      <th>pysent3_Polarity_text.1</th>\n",
       "      <th>pysent3_Subjectivity_text.1</th>\n",
       "      <th>spacy_senti_text.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130000_05660000</td>\n",
       "      <td>20120718</td>\n",
       "      <td>130000</td>\n",
       "      <td>Bernanke</td>\n",
       "      <td>bernanke:  agree that fed needs to be transpar...</td>\n",
       "      <td>bernankeagreethatfedneedstobetransparentandacc...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>10:34:20</td>\n",
       "      <td>...</td>\n",
       "      <td>6.014177e-06</td>\n",
       "      <td>0.186004</td>\n",
       "      <td>0.014144</td>\n",
       "      <td>0.799853</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6.014177e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130000_05680000</td>\n",
       "      <td>20120718</td>\n",
       "      <td>130000</td>\n",
       "      <td>Bernanke</td>\n",
       "      <td>bernanke:  would argue that the fed is already...</td>\n",
       "      <td>bernankewouldarguethatthefedisalreadyquitetran...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>10:34:40</td>\n",
       "      <td>...</td>\n",
       "      <td>5.653985e-08</td>\n",
       "      <td>0.117009</td>\n",
       "      <td>0.102258</td>\n",
       "      <td>0.780733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.653985e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130000_05690000</td>\n",
       "      <td>20120718</td>\n",
       "      <td>130000</td>\n",
       "      <td>Bernanke</td>\n",
       "      <td>bernanke: gao has extensive, broad authority t...</td>\n",
       "      <td>bernankegaohasextensivebroadauthoritytoauditth...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>10:34:50</td>\n",
       "      <td>...</td>\n",
       "      <td>7.758295e-01</td>\n",
       "      <td>0.101995</td>\n",
       "      <td>0.011845</td>\n",
       "      <td>0.886160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>7.758295e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130000_05800000</td>\n",
       "      <td>20120718</td>\n",
       "      <td>130000</td>\n",
       "      <td>Bernanke</td>\n",
       "      <td>bernanke: it's a mistake to subject monetary p...</td>\n",
       "      <td>bernankeitsamistaketosubjectmonetarypolicydeli...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>10:36:40</td>\n",
       "      <td>...</td>\n",
       "      <td>7.477073e-02</td>\n",
       "      <td>0.022089</td>\n",
       "      <td>0.638846</td>\n",
       "      <td>0.339065</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>7.477073e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130000_05860000</td>\n",
       "      <td>20120718</td>\n",
       "      <td>130000</td>\n",
       "      <td>Bernanke</td>\n",
       "      <td>bernanke: would be concerning if monetary poli...</td>\n",
       "      <td>bernankewouldbeconcerningifmonetarypolicydelib...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>10:37:40</td>\n",
       "      <td>...</td>\n",
       "      <td>7.195666e-01</td>\n",
       "      <td>0.024614</td>\n",
       "      <td>0.092775</td>\n",
       "      <td>0.882611</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>7.195666e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timestamp 1      date  9am est stamp fed chair  \\\n",
       "0  130000_05660000  20120718         130000  Bernanke   \n",
       "1  130000_05680000  20120718         130000  Bernanke   \n",
       "2  130000_05690000  20120718         130000  Bernanke   \n",
       "3  130000_05800000  20120718         130000  Bernanke   \n",
       "4  130000_05860000  20120718         130000  Bernanke   \n",
       "\n",
       "                                                text  \\\n",
       "0  bernanke:  agree that fed needs to be transpar...   \n",
       "1  bernanke:  would argue that the fed is already...   \n",
       "2  bernanke: gao has extensive, broad authority t...   \n",
       "3  bernanke: it's a mistake to subject monetary p...   \n",
       "4  bernanke: would be concerning if monetary poli...   \n",
       "\n",
       "                                        standardized  \\\n",
       "0  bernankeagreethatfedneedstobetransparentandacc...   \n",
       "1  bernankewouldarguethatthefedisalreadyquitetran...   \n",
       "2  bernankegaohasextensivebroadauthoritytoauditth...   \n",
       "3  bernankeitsamistaketosubjectmonetarypolicydeli...   \n",
       "4  bernankewouldbeconcerningifmonetarypolicydelib...   \n",
       "\n",
       "   policy ind (1=testimony related, 0=not policy related, 99=other  \\\n",
       "0                                                  1                 \n",
       "1                                                  1                 \n",
       "2                                                  1                 \n",
       "3                                                  1                 \n",
       "4                                                  1                 \n",
       "\n",
       "  topic indicator  type of news indicator first timestamp of group  ...  \\\n",
       "0                                       4                 10:34:20  ...   \n",
       "1                                       4                 10:34:40  ...   \n",
       "2                                       4                 10:34:50  ...   \n",
       "3                                       4                 10:36:40  ...   \n",
       "4                                       4                 10:37:40  ...   \n",
       "\n",
       "  spacy_senti_text  finbert_neutral_text.1 finbert_positive_text.1  \\\n",
       "0     6.014177e-06                0.186004                0.014144   \n",
       "1     5.653985e-08                0.117009                0.102258   \n",
       "2     7.758295e-01                0.101995                0.011845   \n",
       "3     7.477073e-02                0.022089                0.638846   \n",
       "4     7.195666e-01                0.024614                0.092775   \n",
       "\n",
       "   finbert_negative_text.1  ahkz_score_text.1  pysent3_Positive_text.1  \\\n",
       "0                 0.799853                  0                      1.0   \n",
       "1                 0.780733                  0                      0.0   \n",
       "2                 0.886160                  0                      1.0   \n",
       "3                 0.339065                  0                      0.0   \n",
       "4                 0.882611                  0                      0.0   \n",
       "\n",
       "  pysent3_Negative_text.1 pysent3_Polarity_text.1  \\\n",
       "0                     2.0               -0.333333   \n",
       "1                     3.0               -1.000000   \n",
       "2                     1.0                0.000000   \n",
       "3                     2.0               -1.000000   \n",
       "4                     2.0               -1.000000   \n",
       "\n",
       "   pysent3_Subjectivity_text.1 spacy_senti_text.1  \n",
       "0                     0.333333       6.014177e-06  \n",
       "1                     0.333333       5.653985e-08  \n",
       "2                     0.222222       7.758295e-01  \n",
       "3                     0.181818       7.477073e-02  \n",
       "4                     0.181818       7.195666e-01  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f75b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
